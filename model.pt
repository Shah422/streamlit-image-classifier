import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from torchsummary import summary
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import numpy as np


# ===== Device setup =====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ===== Number of classes for your classification task =====
# num_classes = 10  # Change as needed - This is now defined from the data
num_classes = len(class_names) # Use the actual number of classes from the dataset

# ===== Load pre-trained models without the top layers =====
# VGG16
vgg_base = models.vgg16(pretrained=True)
vgg_base.classifier = nn.Identity()  # Remove original classifier

# ResNet50
resnet_base = models.resnet50(pretrained=True)
# Remove the fully connected layer and the preceding AdaptiveAvgPool2d
# We will handle pooling and flattening in the CustomModel's forward method
resnet_base = nn.Sequential(*(list(resnet_base.children())[:-2]))


# ===== Add custom classification head =====
class CustomModel(nn.Module):
    def __init__(self, base_model, base_out_features):
        super(CustomModel, self).__init__()
        self.base = base_model
        # Add pooling and flatten layers here, and apply conditionally in forward
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        self.flatten = nn.Flatten()
        self.classifier = nn.Sequential(
            nn.Linear(base_out_features, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )


    def forward(self, x):
        x = self.base(x)
        # Check if the output has spatial dimensions (more than 2 dimensions: Batch, Features)
        if x.dim() > 2:
            x = self.pool(x)
            x = self.flatten(x)
        x = self.classifier(x)
        return x

# For VGG16, the output from base is (batch, 512, 7, 7)
# Weâ€™ll use AdaptiveAvgPool2d to make it (batch, 512, 1, 1)
vgg_model = CustomModel(vgg_base.features, base_out_features=512)
# For ResNet50 after removing the last two layers, the output is (batch, 2048, 7, 7)
# The CustomModel's forward method will handle the pooling and flattening
resnet_model = CustomModel(resnet_base, base_out_features=2048)

vgg_model = vgg_model.to(device)
resnet_model = resnet_model.to(device)

# ===== Freeze base model layers for initial training =====
def freeze_base_layers(model):
    for param in model.base.parameters():
        param.requires_grad = False

freeze_base_layers(vgg_model)
freeze_base_layers(resnet_model)

# ===== Define loss and optimizer =====
criterion = nn.CrossEntropyLoss()
optimizer_vgg = torch.optim.Adam(filter(lambda p: p.requires_grad, vgg_model.parameters()), lr=1e-3)
optimizer_resnet = torch.optim.Adam(filter(lambda p: p.requires_grad, resnet_model.parameters()), lr=1e-3)

# ===== OPTIONAL: Fine-tuning later layers =====
def unfreeze_last_layers(model, num_layers_to_unfreeze=5):
    # Unfreeze the last N layers in base
    layers = list(model.base.children())
    if hasattr(model.base, 'features'):  # VGG
        layers = list(model.base.features.children())
    for layer in layers[-num_layers_to_unfreeze:]:
        for param in layer.parameters():
            param.requires_grad = True

    # Lower learning rate for fine-tuning
    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)
    return optimizer

# Example usage (after initial training):
# optimizer_vgg = unfreeze_last_layers(vgg_model, num_layers_to_unfreeze=5)
# optimizer_resnet = unfreeze_last_layers(resnet_model, num_layers_to_unfreeze=5)

# ===== Optional: Summary of model =====
summary(vgg_model, input_size=(3, 224, 224))
summary(resnet_model, input_size=(3, 224, 224))



# Store metrics
def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=5):
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []

    for epoch in range(epochs):
        model.train()
        total_loss, correct, total = 0.0, 0, 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        train_acc = correct / total
        train_loss = total_loss / len(train_loader)
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # Validation
        val_loss, val_acc = evaluate_model(model, criterion, val_loader)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    return train_losses, val_losses, train_accuracies, val_accuracies

def evaluate_model(model, criterion, dataloader):
    model.eval()
    total_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return total_loss / len(dataloader), correct / total

def plot_confusion_matrix(model, dataloader, class_names):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=class_names, yticklabels=class_names, cmap="Blues")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix")
    plt.show()

    print("\nClassification Report:\n")
    print(classification_report(all_labels, all_preds, target_names=class_names))

def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):
    epochs = range(1, len(train_losses)+1)

    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, 'b-', label='Training Loss')
    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss over Epochs')

    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accuracies, 'b-', label='Training Acc')
    plt.plot(epochs, val_accuracies, 'r-', label='Validation Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Accuracy over Epochs')

    plt.tight_layout()
    plt.show()



def visualize_predictions(model, dataloader, class_names, num_images=5):
    model.eval()
    images_shown = 0

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            probs = torch.softmax(outputs, dim=1)
            _, preds = torch.max(probs, 1)

            for i in range(inputs.size(0)):
                if images_shown >= num_images:
                    return

                img = inputs[i].cpu().permute(1, 2, 0).numpy()
                img = (img - img.min()) / (img.max() - img.min())

                plt.imshow(img)
                plt.axis('off')
                pred_class = class_names[preds[i]]
                true_class = class_names[labels[i]]
                prob = probs[i][preds[i]].item()
                color = 'green' if pred_class == true_class else 'red'
                plt.title(f"Pred: {pred_class} ({prob:.2f})\nTrue: {true_class}", color=color)
                plt.show()

                images_shown += 1



# After training:
# Example training with VGG model
train_losses, val_losses, train_accs, val_accs = train_model(vgg_model, criterion, optimizer_vgg, dataloaders['train'], dataloaders['val'], epochs=10)

# Plot metrics
plot_training_curves(train_losses, val_losses, train_accs, val_accs)

# Evaluate
# Use the validation dataloader for evaluation
plot_confusion_matrix(vgg_model, dataloaders['val'], class_names)
visualize_predictions(vgg_model, dataloaders['val'], class_names, num_images=5)
